{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02cbb46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training dataset...\n",
      "Training dataset loaded.\n",
      "Iteration 1, loss = 0.03732795\n",
      "Validation score: 0.957708\n",
      "Iteration 2, loss = 0.00248891\n",
      "Validation score: 0.981213\n",
      "Iteration 3, loss = 0.00143567\n",
      "Validation score: 0.986022\n",
      "Iteration 4, loss = 0.00117968\n",
      "Validation score: 0.987524\n",
      "Iteration 5, loss = 0.00107631\n",
      "Validation score: 0.988841\n",
      "Iteration 6, loss = 0.00096650\n",
      "Validation score: 0.989985\n",
      "Iteration 7, loss = 0.00084471\n",
      "Validation score: 0.990913\n",
      "Iteration 8, loss = 0.00073179\n",
      "Validation score: 0.992743\n",
      "Iteration 9, loss = 0.00060521\n",
      "Validation score: 0.993817\n",
      "Iteration 10, loss = 0.00051058\n",
      "Validation score: 0.994619\n",
      "Iteration 11, loss = 0.00045541\n",
      "Validation score: 0.995050\n",
      "Iteration 12, loss = 0.00042067\n",
      "Validation score: 0.995431\n",
      "Iteration 13, loss = 0.00039361\n",
      "Validation score: 0.995597\n",
      "Iteration 14, loss = 0.00036797\n",
      "Validation score: 0.995931\n",
      "Iteration 15, loss = 0.00034437\n",
      "Validation score: 0.995902\n",
      "Iteration 16, loss = 0.00033814\n",
      "Validation score: 0.996269\n",
      "Iteration 17, loss = 0.00031952\n",
      "Validation score: 0.996248\n",
      "Iteration 18, loss = 0.00031007\n",
      "Validation score: 0.996516\n",
      "Iteration 19, loss = 0.00029524\n",
      "Validation score: 0.996522\n",
      "Iteration 20, loss = 0.00027478\n",
      "Validation score: 0.996813\n",
      "Iteration 21, loss = 0.00025924\n",
      "Validation score: 0.997225\n",
      "Iteration 22, loss = 0.00024425\n",
      "Validation score: 0.997360\n",
      "Iteration 23, loss = 0.00023424\n",
      "Validation score: 0.997460\n",
      "Iteration 24, loss = 0.00021398\n",
      "Validation score: 0.997304\n",
      "Iteration 25, loss = 0.00021293\n",
      "Validation score: 0.997676\n",
      "Iteration 26, loss = 0.00021906\n",
      "Validation score: 0.997779\n",
      "Iteration 27, loss = 0.00019577\n",
      "Validation score: 0.997741\n",
      "Iteration 28, loss = 0.00019743\n",
      "Validation score: 0.997888\n",
      "Iteration 29, loss = 0.00018453\n",
      "Validation score: 0.997581\n",
      "Iteration 30, loss = 0.00018307\n",
      "Validation score: 0.997785\n",
      "Iteration 31, loss = 0.00017937\n",
      "Validation score: 0.998071\n",
      "Iteration 32, loss = 0.00017862\n",
      "Validation score: 0.997885\n",
      "Iteration 33, loss = 0.00017564\n",
      "Validation score: 0.997367\n",
      "Iteration 34, loss = 0.00017875\n",
      "Validation score: 0.998080\n",
      "Iteration 35, loss = 0.00018777\n",
      "Validation score: 0.998105\n",
      "Iteration 36, loss = 0.00017573\n",
      "Validation score: 0.998302\n",
      "Iteration 37, loss = 0.00017747\n",
      "Validation score: 0.998370\n",
      "Iteration 38, loss = 0.00016576\n",
      "Validation score: 0.998119\n",
      "Iteration 39, loss = 0.00016301\n",
      "Validation score: 0.998287\n",
      "Iteration 40, loss = 0.00017581\n",
      "Validation score: 0.998073\n",
      "Iteration 41, loss = 0.00015879\n",
      "Validation score: 0.998282\n",
      "Iteration 42, loss = 0.00016107\n",
      "Validation score: 0.998366\n",
      "Iteration 43, loss = 0.00014459\n",
      "Validation score: 0.998295\n",
      "Iteration 44, loss = 0.00018574\n",
      "Validation score: 0.998613\n",
      "Iteration 45, loss = 0.00016437\n",
      "Validation score: 0.998388\n",
      "Iteration 46, loss = 0.00013558\n",
      "Validation score: 0.998671\n",
      "Iteration 47, loss = 0.00019403\n",
      "Validation score: 0.998606\n",
      "Iteration 48, loss = 0.00013723\n",
      "Validation score: 0.998666\n",
      "Iteration 49, loss = 0.00014004\n",
      "Validation score: 0.998647\n",
      "Iteration 50, loss = 0.00013836\n",
      "Validation score: 0.998617\n",
      "Iteration 51, loss = 0.00016597\n",
      "Validation score: 0.998116\n",
      "Iteration 52, loss = 0.00013984\n",
      "Validation score: 0.998783\n",
      "Iteration 53, loss = 0.00013927\n",
      "Validation score: 0.998519\n",
      "Iteration 54, loss = 0.00015150\n",
      "Validation score: 0.998514\n",
      "Iteration 55, loss = 0.00013285\n",
      "Validation score: 0.997680\n",
      "Iteration 56, loss = 0.00014662\n",
      "Validation score: 0.997948\n",
      "Iteration 57, loss = 0.00016290\n",
      "Validation score: 0.997778\n",
      "Iteration 58, loss = 0.00012462\n",
      "Validation score: 0.998607\n",
      "Iteration 59, loss = 0.00013007\n",
      "Validation score: 0.998852\n",
      "Iteration 60, loss = 0.00013083\n",
      "Validation score: 0.998344\n",
      "Iteration 61, loss = 0.00013837\n",
      "Validation score: 0.998293\n",
      "Iteration 62, loss = 0.00014885\n",
      "Validation score: 0.998785\n",
      "Iteration 63, loss = 0.00013325\n",
      "Validation score: 0.998844\n",
      "Iteration 64, loss = 0.00012517\n",
      "Validation score: 0.998204\n",
      "Iteration 65, loss = 0.00013356\n",
      "Validation score: 0.998193\n",
      "Iteration 66, loss = 0.00015591\n",
      "Validation score: 0.997758\n",
      "Iteration 67, loss = 0.00013455\n",
      "Validation score: 0.998845\n",
      "Iteration 68, loss = 0.00011982\n",
      "Validation score: 0.998572\n",
      "Iteration 69, loss = 0.00012516\n",
      "Validation score: 0.998722\n",
      "Iteration 70, loss = 0.00011950\n",
      "Validation score: 0.999005\n",
      "Iteration 71, loss = 0.00013571\n",
      "Validation score: 0.998940\n",
      "Iteration 72, loss = 0.00010925\n",
      "Validation score: 0.998940\n",
      "Iteration 73, loss = 0.00014111\n",
      "Validation score: 0.997509\n",
      "Iteration 74, loss = 0.00011951\n",
      "Validation score: 0.998741\n",
      "Iteration 75, loss = 0.00012155\n",
      "Validation score: 0.998882\n",
      "Iteration 76, loss = 0.00011860\n",
      "Validation score: 0.998768\n",
      "Iteration 77, loss = 0.00012438\n",
      "Validation score: 0.998913\n",
      "Iteration 78, loss = 0.00011713\n",
      "Validation score: 0.998863\n",
      "Iteration 79, loss = 0.00011043\n",
      "Validation score: 0.998817\n",
      "Iteration 80, loss = 0.00014210\n",
      "Validation score: 0.998860\n",
      "Iteration 81, loss = 0.00010667\n",
      "Validation score: 0.998984\n",
      "Validation score did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
      "0.9999264231597524\n",
      "0.9983193910294023\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import h5py\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "# disable FutureWarning\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "train_data_path='./Training_Data/'\n",
    "output_path='./net/'\n",
    "\n",
    "nnstr='Ozone' #NN name string\n",
    "hiddenlayers=(100,90,75) #set MLNN hidden layers (hidden layers will be reset for aaNN based on number of bands)\n",
    "\n",
    "#radoption=2 #TOA rad data type, options: 1=Lt, 2=Lrc \n",
    "addnoise=0 #Flag for adding Gaussian noise NOTE: do not add noise for forward training\n",
    "noiselevel=0 #Gaussian noise level, e.g. 1=1%\n",
    "\n",
    "#sensor band infos\n",
    "band=[302,312,320,340,380]\n",
    "trainband=np.arange(5)\n",
    "nrrs=5\n",
    "aodidx=np.arange(5)\n",
    "\n",
    "#number of sample in the scatter plot, if total number of data points is less than this, half of the data will be used for plotting\n",
    "nplotsample=5000 \n",
    "\t\n",
    "nband=len(band)\n",
    "ntrainband=len(trainband)\n",
    "naod=len(aodidx) \n",
    "      \n",
    "#read in training data\n",
    "print('Loading training dataset...')\n",
    "for i in np.arange(5):\n",
    "    if i==0:       \n",
    "       par=np.loadtxt(train_data_path +'NILU-training'+str(i+1)+'.txt')\n",
    "    else:\n",
    "       par=np.append(par,np.loadtxt(train_data_path +'NILU-training'+str(i+1)+'.txt'),0)\n",
    "\n",
    "print('Training dataset loaded.')\n",
    "\n",
    "\n",
    "\n",
    "#remove negative values\n",
    "idx=np.where(np.sum(par<0,axis=1)==0)[0]\n",
    "par=par[idx,:]\n",
    "\n",
    "#total number of training cases\n",
    "ncase=len(par)\n",
    "rad=np.zeros((ncase,1))\n",
    "\n",
    "#rad[:,0] = par[:,3]\n",
    "#rad[:,1] = par[:,4]\n",
    "\n",
    "#generate the gaussian noise for each band\n",
    "if addnoise==1:\n",
    "    fname_prefix=nnstr+'WiGN_p'+str(noiselevel)\n",
    "    noise=np.random.normal(1,noiselevel/100,(ncase,1))    # only use 2 ratio\n",
    "    rad=np.multiply(rad,noise) \n",
    "else:\n",
    "    fname_prefix=nnstr+'WoGN' \n",
    "     \n",
    "# NN training: Ozone & Cloud Optical Depth   \n",
    "#trainingoption = itrain + 1\n",
    "\n",
    "nnlayer = hiddenlayers\n",
    "            \n",
    "nlayer=len(nnlayer) # number of hidden layers\n",
    "    \n",
    "#create layer string for file name\n",
    "layerstr=''\n",
    "for i in np.arange(nlayer):\n",
    "    if i<nlayer-1:\n",
    "       layerstr=layerstr+str(nnlayer[i])+'X'\n",
    "    else:\n",
    "       layerstr=layerstr+str(nnlayer[i])\n",
    "\n",
    "trainx=np.zeros((ncase,3))\n",
    "trainy=np.zeros((ncase,2))\n",
    "\n",
    "trainx[:,0]=np.cos(np.deg2rad(par[:,0])) # geometry: cos[Solar Zenith Angle]\n",
    "trainx[:,1]=np.log10(par[:,3]) # Irradiance 380\n",
    "trainx[:,2]=np.log10(par[:,4]) # Ratio\n",
    "\n",
    "trainy[:,0]=np.log10(par[:,1]) # Ozone\n",
    "trainy[:,1]=np.log10(par[:,2]) # Cloud. Vol. Frac.\n",
    "\n",
    "net_name='net_'+fname_prefix+'_ozone'+str(nrrs)+'_'+layerstr+'.h5'\t  \n",
    "for i in np.arange(nrrs):\n",
    "    if i==0:\n",
    "       labelparam=['Rrs'+str(band[i])+'nm']\n",
    "    else:\n",
    "       labelparam=np.append(labelparam,['Rrs'+str(band[i])+'nm'],0)\t\t\t  \n",
    "\n",
    "ninput=len(trainx[0])\n",
    "train_in=np.zeros((ninput,2))\n",
    "for i in range(ninput):\n",
    "    train_in[i,0]=trainx[:,i].min()\n",
    "    train_in[i,1]=trainx[:,i].max()\n",
    "noutput=len(trainy[0])\t\n",
    "train_out=np.zeros((noutput,2))\n",
    "for i in range(noutput):\n",
    "    train_out[i,0]=trainy[:,i].min()\n",
    "    train_out[i,1]=trainy[:,i].max()\n",
    "#normalize the trainx and trainy to [-1,1]\t\n",
    "for i in range(ninput):\n",
    "    trainx[:,i]=2*(trainx[:,i]-train_in[i,0])/(train_in[i,1]-train_in[i,0])-1\n",
    "for i in range(noutput):\n",
    "    trainy[:,i]=2*(trainy[:,i]-train_out[i,0])/(train_out[i,1]-train_out[i,0])-1\n",
    "\t\n",
    "#Build MLNN\n",
    "mlnn=MLPRegressor(hidden_layer_sizes=nnlayer,\n",
    "     activation='tanh',\n",
    "\t  solver='adam',\n",
    "    \t  batch_size='auto',\n",
    "    \t  learning_rate='adaptive',\n",
    "    \t  learning_rate_init=0.001,\n",
    "    \t  max_iter=1000,\n",
    "    \t  random_state=5,\n",
    "    \t  tol=1.0e-8,\n",
    "    \t  verbose=True,\n",
    "    \t  early_stopping=True,  \n",
    "    \t  validation_fraction=0.1)\n",
    "#traing MLNN\n",
    "mlnn=mlnn.fit(trainx,trainy)\n",
    "    \n",
    "#save trained NN to HDF5\n",
    "nn_structure=np.zeros([nlayer+2])\n",
    "nn_structure[0]=ninput\n",
    "for i in range(nlayer):\n",
    "    nn_structure[i+1]=nnlayer[i]\n",
    "nn_structure[nlayer+1]=noutput\n",
    "    \n",
    "hf = h5py.File('./net/'+net_name,'w')\n",
    "hf.create_dataset('Layers',dtype='int8',data = nn_structure)\n",
    "hf.create_dataset('Norm_in',dtype='float64',data = train_in)\n",
    "hf.create_dataset('Norm_out',dtype='float64',data = train_out)\n",
    "gw = hf.create_group('Weights')\n",
    "for i in range(nlayer+1):    \n",
    "    gw.create_dataset('Layer'+str(i+1),dtype='float64',data=np.transpose(mlnn.coefs_[i]))\n",
    "gb = hf.create_group('Bias')\n",
    "for i in range(nlayer+1):\n",
    "    gb.create_dataset('Layer'+str(i+1),dtype='float64',data=mlnn.intercepts_[i].reshape(int(nn_structure[i+1]),1))\n",
    "hf.close()   \n",
    "\n",
    "#make prediction using trained MLNN\n",
    "nnoutput=mlnn.predict(trainx)\n",
    "#converting data\n",
    "for i in range(noutput):\n",
    "    nnoutput[:,i]=(nnoutput[:,i]+1)/2*(train_out[i,1]-train_out[i,0])+train_out[i,0]\n",
    "    trainy[:,i]=(trainy[:,i]+1)/2*(train_out[i,1]-train_out[i,0])+train_out[i,0]\n",
    "\t\n",
    "nnoutput=10 ** nnoutput\n",
    "trainy=10 ** trainy\n",
    "    \n",
    "#compute average percentage error\n",
    "diff=(nnoutput-trainy)/trainy*100\n",
    "ape=np.mean(np.absolute(diff), axis=0)\n",
    "bias=np.mean(diff, axis=0)\n",
    "    \n",
    "lim=np.amax(trainy,axis=0)*1.2 #set limit\n",
    "r2=np.zeros(noutput)\n",
    "if ncase>nplotsample:\n",
    "    idx=random.sample(list(range(ncase)),nplotsample)\n",
    "else:\n",
    "    idx=random.sample(list(range(ncase)),int(ncase/2))\n",
    "if noutput<5:\n",
    "    plt.figure(figsize=(18,5),dpi=150)\n",
    "else:\n",
    "    plt.figure(figsize=(18,9),dpi=150)\n",
    "for i in np.arange(noutput):\n",
    "    r2[i]=r2_score(trainy[:,i],nnoutput[:,i])\n",
    "    print(r2[i])\n",
    "    plt.subplot(2,4,i+1)           \n",
    "    plt.scatter(trainy[idx,i],nnoutput[idx,i],s=2,c='red')\n",
    "    plt.xlim(0, lim[i])\n",
    "    plt.ylim(0, lim[i])\n",
    "    plt.xlabel('Model '+labelparam[i]) #original line:   plt.xlabel('Model '+labelparam[i])\n",
    "    plt.ylabel('MLNN '+labelparam[i])  #original line: plt.ylabel('MLNN '+labelparam[i])\n",
    "    plt.plot([0,lim[i]],[0,lim[i]],'k')\n",
    "    plt.text(lim[i]*0.05,lim[i]*0.94,('R$^2$ = %0.3f' % (r2[i])))\n",
    "    plt.text(lim[i]*0.05,lim[i]*0.88,('APE = %0.2f' % (ape[i])+'%'))\n",
    "    plt.text(lim[i]*0.05,lim[i]*0.82,('Bias = %0.2f' % (bias[i])+'%'))\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_path+net_name+'_Training.png')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33da37fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
